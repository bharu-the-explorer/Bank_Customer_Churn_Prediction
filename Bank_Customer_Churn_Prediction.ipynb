{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING LIBRARIES\n"
      ],
      "metadata": {
        "id": "VQ1yGqOXS31k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGrZq91wEbLj"
      },
      "outputs": [],
      "source": [
        "# General\n",
        "import pickle\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns',None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "\n",
        "# Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"font.family\"] = \"Sans\"\n",
        "plt.style.use('seaborn-poster')\n",
        "\n",
        "\n",
        "# Seaborn\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split,cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.preprocessing import scale,StandardScaler,MinMaxScaler,Normalizer,RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "\n",
        "# Sklearn Metrics and Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import  accuracy_score, f1_score,precision_score,confusion_matrix, recall_score, roc_auc_score\n",
        "\n",
        "# LightGBM\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "#XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# CatBoost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Statistics Testing\n",
        "from scipy import stats\n",
        "from scipy.stats import f_oneway\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "import scikitplot as skplt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Information, Feature Checking, and Analysis"
      ],
      "metadata": {
        "id": "ukMG055YTAD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataInfo(X):\n",
        "    print('='*10, 'DATA & FEATURE INFORMATION', '='*10)\n",
        "    print(f'Data Rows: {X.shape[0]}')\n",
        "    print(f'Data Columns: {X.shape[1]}')\n",
        "    print(f'Duplicated Values: {X.duplicated().sum()}')\n",
        "    missing_val = X.isnull().sum()\n",
        "    missing_val_percentage = missing_val/len(X)*100\n",
        "    data_type = X.dtypes\n",
        "    unique_val = X.nunique()\n",
        "    return pd.DataFrame({\n",
        "        'Missing_val' : missing_val,\n",
        "        'Missing_percentage' : missing_val_percentage,\n",
        "        'Data_type' : data_type,\n",
        "        'Unique_values' : unique_val\n",
        "    }).sort_values('Missing_percentage',ascending=False)"
      ],
      "metadata": {
        "id": "HTzZye7nS23y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Outlier in Data and Returning It"
      ],
      "metadata": {
        "id": "P2_n885RT3z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataOutlier(X, col):\n",
        "    q1 = X[col].quantile(0.25) # Finding the first quartile\n",
        "    q3 = X[col].quantile(0.75) # Finding the third quartile\n",
        "    iqr_val = stats.iqr(X[col]) # Finding the interquartile range\n",
        "    loYour = q1 - (1.5*iqr_val) # LoYour limit for detecting outliers\n",
        "in the data\n",
        "\n",
        "\n",
        "    upper = q3 + (1.5*iqr_val) # Upper limit for detecting outliers in the data\n",
        "\n",
        "    outlier_list = X[col].apply(lambda x: 'outlier' if x < loYour or x > upper else 'not-outlier')\n",
        "    print(f'outlier loYour limit: {loYour}\\noutlier upper limit:{upper}')\n",
        "    return outlier_list"
      ],
      "metadata": {
        "id": "zfc0K7NPT3GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Outlier Using LOF method"
      ],
      "metadata": {
        "id": "G1VVpVmET8Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lof_observation(df):\n",
        "    # Define numeric data types\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "    # Select numeric columns\n",
        "    df_num_cols = df.select_dtypes(include=numerics)\n",
        "\n",
        "    # Convert to float\n",
        "    df_outlier = df_num_cols.astype(\"float64\")\n",
        "\n",
        "    # Initialize Local Outlier Factor\n",
        "    clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "\n",
        "    # Fit the model and get the outlier scores\n",
        "    clf.fit_predict(df_outlier)\n",
        "    df_scores = clf.negative_outlier_factor_\n",
        "\n",
        "    # Create a DataFrame for outlier scores\n",
        "    scores_df = pd.DataFrame(np.sort(df_scores))\n",
        "\n",
        "    # Plot visualization of outliers\n",
        "    scores_df.plot(stacked=True, xlim=[0, 20], color='r',\n",
        "                   title='Visualization of outliers according to the LOF method', style='.-')\n",
        "\n",
        "    # Determine the threshold value for outliers\n",
        "    th_val = np.sort(df_scores)[2]\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = df_scores > th_val\n",
        "\n",
        "    # Drop outliers from the original DataFrame\n",
        "    df_cleaned = df.drop(df_outlier[~outliers].index)\n",
        "\n",
        "    # Return the cleaned DataFrame shape\n",
        "    return df_cleaned"
      ],
      "metadata": {
        "id": "sjLB0DpUT-u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returning Unique Values in Data"
      ],
      "metadata": {
        "id": "iY6pDo4cUIb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataUnique(X):\n",
        "    for x in X.columns:\n",
        "        print(f'========== {x} ==========')\n",
        "        print(f'{X[x].unique()}\\n') # Printing all the unique values in the columns"
      ],
      "metadata": {
        "id": "EQ07RX5YUBH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Visualization (Used Mostly to See The Data Distribution and\n",
        "Outlier Existence)"
      ],
      "metadata": {
        "id": "B7iCGO_BUNaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hist_boxplot(df, x_col, y_col=None, hue_col=None):\n",
        "    color = '#F84030'\n",
        "    if y_col is None:\n",
        "        plt.figure(figsize=(10,10))\n",
        "        plt.subplot(211)\n",
        "        sns.boxplot(data=df, x=x_col, color=color)\n",
        "\n",
        "        plt.subplot(212)\n",
        "\n",
        "        sns.histplot(data=df, x=x_col, color=color)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    elif hue_col is None:\n",
        "        plt.figure(figsize=(10,10))\n",
        "        plt.subplot(211)\n",
        "        sns.boxplot(data=df, x=x_col, y=y_col, color=color)\n",
        "\n",
        "        plt.subplot(212)\n",
        "        sns.histplot(data=df, x=x_col, y=y_col, color=color)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        plt.figure(figsize=(10,10))\n",
        "        plt.subplot(211)\n",
        "        sns.boxplot(data=df, x=x_col, y=y_col, hue=hue_col, color=color)\n",
        "\n",
        "        plt.subplot(212)\n",
        "        sns.histplot(data=df, x=x_col, y=y_col, hue=hue_col,color=color)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "aG6DrBvFULaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another Data Visualization (Used to See The Corelation of Certain\n",
        "Variable, Mostly Between Predictor and Target)"
      ],
      "metadata": {
        "id": "oD3QYHAdURj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#catergoric vs categoric\n",
        "#predictor,target\n",
        "def plot_category_category(df, predictor, target):\n",
        "    ax = ((df.groupby([predictor])[target].mean())/((df.groupby([predictor])[target].mean()).sum())*100).plot(kind='bar',figsize=(10,8), color ='#F84030')\n",
        "    abs_values = round(((df.groupby([predictor])[target].mean())/((df.groupby([predictor])[target].mean()).sum())*100),1)ax.bar_label(container=ax.containers[0], labels=abs_values)\n",
        "\n",
        "    plt.xticks(rotation=0);\n",
        "    plt.ylabel('Churn Rate (%)',fontsize=12)\n",
        "    plt.title(f'{predictor} vs Churn Rate (%)',fontsize=12)\n",
        "    plt.xlabel(predictor,fontsize=12)\n",
        "    plt.ylim(0,100)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_num_category(df, numeric, category):\n",
        "\n",
        "    ax = (df.groupby([category])[numeric].median()).plot(kind='bar',figsize=(10,8), color = '#F84030')\n",
        "    abs_values = round((df.groupby([category])[numeric].median()),1)\n",
        "    ax.bar_label(container=ax.containers[0], labels=abs_values)\n",
        "\n",
        "    plt.title(f'{numeric} vs {category}',fontsize=12)\n",
        "    plt.ylabel(category,fontsize=12)\n",
        "    plt.xlabel(numeric,fontsize=12)\n",
        "    plt.xticks(rotation=0);\n",
        "    plt.ylim(0,max(abs_values)+100)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gIcLayvdUUDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Analysis (Analysis of Variance and Chi-Square Test)"
      ],
      "metadata": {
        "id": "hVC3i-TKUYHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anova(df, predictor_col, target_col):\n",
        "    group1 = df[df[target_col]==1][predictor_col]\n",
        "    group2 = df[df[target_col]==0][predictor_col]\n",
        "\n",
        "    alpha = 0.05\n",
        "    ftest, p_value = f_oneway(group1, group2)\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(f'Conclusion: p-value {p_value} is less than alpha {alpha}, ftest = {ftest}')\n",
        "        print('There is a significant difference in the target based on the predictor.')\n",
        "        print()\n",
        "    else:\n",
        "        print(f'Conclusion: p-value {p_value} is greater than alpha {alpha}, ftest = {ftest}')\n",
        "        print('There is no significant difference in the target based on the predictor.')\n",
        "        print()\n",
        "def chi_test(df, predictor_col, target_col):\n",
        "    obs = pd.crosstab(df[predictor_col], df[target_col])\n",
        "    chi2, p, dof, expected = chi2_contingency(obs)\n",
        "    alpha = 0.05\n",
        "\n",
        "    if p < alpha:\n",
        "        print(f'===== {predictor_col} =====')\n",
        "        print('Number Expected:')\n",
        "        print(expected)\n",
        "        print()\n",
        "        print(f'Chi-square Statistic: {chi2}, p-value: {p} less than{alpha}')\n",
        "        print('There is a significant difference in the target based on the predictor.')\n",
        "        print()\n",
        "    else:\n",
        "        print(f'===== {predictor_col} =====')\n",
        "        print('Number Expected:')\n",
        "\n",
        "        print(expected)\n",
        "        print()\n",
        "        print(f'Chi-square Statistic: {chi2}, p-value: {p} greater than {alpha}')\n",
        "        print('There is no significant difference in the target based on the predictor.')\n",
        "        print()"
      ],
      "metadata": {
        "id": "oI0zepSxUaoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "6pTsWxe8Uerp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "mQpxMRBSUnsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/Churn_Modelling.csv')\n",
        "TARGET = \"Exited\"\n",
        "data_new = data.copy()\n",
        "data_new['Tenure'] =  data_new.Tenure.astype(float)\n",
        "data_new['NumOfProducts'] =  data_new.NumOfProducts.astype(float)"
      ],
      "metadata": {
        "id": "6j2rE9CHUuNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Descriptive Statistics"
      ],
      "metadata": {
        "id": "wFsNqj8TU1Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical = ['CreditScore',\n",
        "             'Age',\n",
        "             'Tenure',\n",
        "             'Balance',\n",
        "             'NumOfProducts',\n",
        "             'EstimatedSalary']\n",
        "categorical =['RowNumber',\n",
        "              'CustomerId',\n",
        "              'Surname',\n",
        "              'Geography',\n",
        "              'Gender',\n",
        "              'HasCrCard',\n",
        "              'IsActiveMember',\n",
        "              'Exited']\n",
        "# Select rows where is 1 (Exited)\n",
        "df_zero = data_new.query('Exited == 1')\n",
        "\n",
        "# Count occurrences of each value\n",
        "counts = df_zero['Exited'].value_counts()\n",
        "\n",
        "plot_exited = pd.DataFrame({'Yes' : counts,'No' : len(data_new) -\n",
        "counts})\n",
        "\n",
        "# Plot as pie chart\n",
        "plot_exited.T.plot(kind = 'pie',subplots=True, legend =False, title =\n",
        "'Exited', figsize = (6,6),colors=['#F84030','#F2F2F2'],\n",
        "        shadow=True,\n",
        "        autopct='%1.1f%%',\n",
        "        textprops={'fontsize': 16})"
      ],
      "metadata": {
        "id": "snalVkLBU4do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "CXOZmTN3U8B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lof_observation(data_new).head()"
      ],
      "metadata": {
        "id": "Al5OsEHHU-mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profile Analysis of The Customer"
      ],
      "metadata": {
        "id": "ODrR3Tl8VDgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CreditScore vs Exited"
      ],
      "metadata": {
        "id": "Nw7_JdgBVHaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_boxplot(data_new,'CreditScore')"
      ],
      "metadata": {
        "id": "UiAlk2A9VKvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Age vs Exited"
      ],
      "metadata": {
        "id": "F4Qd9iJXVNrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_boxplot(data_new,'Age')"
      ],
      "metadata": {
        "id": "1t9jVzsFVPnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Tenure vs Exited"
      ],
      "metadata": {
        "id": "XaGEwUG_VRYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_boxplot(data_new,'Tenure')"
      ],
      "metadata": {
        "id": "RSKKZCj3VTTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. NumOfProducts vs Exited"
      ],
      "metadata": {
        "id": "cpTO7YrYVUxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_boxplot(data_new,'NumOfProducts')"
      ],
      "metadata": {
        "id": "L7U2coeYVWcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. EstimatedSalary vs Exited"
      ],
      "metadata": {
        "id": "lQMSnrixVZ2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_boxplot(data_new,'EstimatedSalary')"
      ],
      "metadata": {
        "id": "BIL7mnknVbYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Geography vs Exited"
      ],
      "metadata": {
        "id": "zj0BUf1cVcyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_category_category(data_new,'Geography',TARGET)"
      ],
      "metadata": {
        "id": "8wXZGIwdVg2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. HasCrCard vs Exited"
      ],
      "metadata": {
        "id": "iqmWPtJ4Vhrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_category_category(data_new,'HasCrCard',TARGET)"
      ],
      "metadata": {
        "id": "GM23eahMVjXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. IsActiveMember vs Exited"
      ],
      "metadata": {
        "id": "IpnHgEVQVkzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_category_category(data_new,'IsActiveMember',TARGET)"
      ],
      "metadata": {
        "id": "SVOkllsNVmfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Gender vs Exited"
      ],
      "metadata": {
        "id": "xN-hr_EwVoFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_category_category(data_new,'Gender',TARGET)"
      ],
      "metadata": {
        "id": "e3e-znsLVqTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outlier Removal and Data Cleaning"
      ],
      "metadata": {
        "id": "_oB_9NzWVsDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_outliers(df):\n",
        "    # Suppress age and credit score\n",
        "    for col in [\"Age\", \"CreditScore\"]:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        loYour = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        print(f\"When {col} is printed below loYour score: {loYour} and upper score: {upper}\")\n",
        "        if col == \"Age\":\n",
        "            df_outlier = df[col][(df[col] > upper)]\n",
        "            df[col][df_outlier.index] = upper\n",
        "        else:\n",
        "            df_outlier = df[col][(df[col] < loYour)]\n",
        "            df[col][df_outlier.index] = loYour\n",
        "    return df\n",
        "\n",
        "def outlier_process(df):\n",
        "    # Process outliers\n",
        "    df_outlier = lof_observation(df=df)\n",
        "    df_outlier = clear_outliers(df=df_outlier)\n",
        "    return df_outlier"
      ],
      "metadata": {
        "id": "3bOWpPZDVvEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Engineering"
      ],
      "metadata": {
        "id": "hHkUhnUgVxge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit Score"
      ],
      "metadata": {
        "id": "yerArPePV0hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def credit_score_table(row):\n",
        "    credit_score = row.CreditScore\n",
        "    if credit_score < 300:\n",
        "        return \"Deep\"\n",
        "    elif credit_score < 500:\n",
        "        return \"Very_Poor\"\n",
        "    elif credit_score < 601:\n",
        "        return \"Poor\"\n",
        "    elif credit_score < 661:\n",
        "        return \"Fair\"\n",
        "    elif credit_score < 781:\n",
        "        return \"Good\"\n",
        "    elif credit_score < 851:\n",
        "        return \"Excellent\"\n",
        "    else:\n",
        "        return \"Top\""
      ],
      "metadata": {
        "id": "ujhGMzkmV2cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age"
      ],
      "metadata": {
        "id": "vDLYTXzUV4Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def age_categorization(age):\n",
        "    if age < 0:\n",
        "        return \"Invalid\"\n",
        "    elif age < 13:\n",
        "        return \"Child\"\n",
        "    elif age < 18:\n",
        "        return \"Teenager\"\n",
        "    elif age < 30:\n",
        "        return \"Young Adult\"\n",
        "    elif age < 60:\n",
        "        return \"Adult\"\n",
        "    else:\n",
        "        return \"Senior\""
      ],
      "metadata": {
        "id": "fqATRaIwV6EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age and Tenure"
      ],
      "metadata": {
        "id": "JgDE24PWl-DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def age_tenure(row):\n",
        "    age = row.Age\n",
        "    tenure = row.Tenure\n",
        "    return age*tenure"
      ],
      "metadata": {
        "id": "XN3vXktzl_7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product and Tenure"
      ],
      "metadata": {
        "id": "93ohKjb6mC8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def product_utilization_rate_by_year(row):\n",
        "    number_of_products = row.NumOfProducts\n",
        "    tenure = row.Tenure\n",
        "\n",
        "    if tenure == 0:\n",
        "        return number_of_products\n",
        "    else:\n",
        "        rate = number_of_products / tenure\n",
        "        return rate"
      ],
      "metadata": {
        "id": "4gMUrBbymFSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product and Salary"
      ],
      "metadata": {
        "id": "BVmcUm0BmHli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def product_utilization_rate_by_estimated_salary(row):\n",
        "    number_of_products = row.NumOfProducts\n",
        "    estimated_salary = row.EstimatedSalary\n",
        "\n",
        "    if estimated_salary == 0:\n",
        "        return \"Undefined\"\n",
        "    else:\n",
        "        rate = number_of_products / estimated_salary\n",
        "        return rate"
      ],
      "metadata": {
        "id": "HhsmPslfmKGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geography and Salary"
      ],
      "metadata": {
        "id": "Tp58WWj_mMPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def countries_monthly_average_salaries(row):\n",
        "    # Monthly average salary taken from\n",
        "https://www.worlddata.info/average-income.php\n",
        "    avg_salaries = {'France': 3680, 'Germany': 4305, 'Spain': 2474}\n",
        "\n",
        "    salary = row.EstimatedSalary / 12\n",
        "    country = row.Geography\n",
        "\n",
        "    if country in avg_salaries:\n",
        "        return salary / avg_salaries[country]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "wUzlQXmGmN_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance and Salary"
      ],
      "metadata": {
        "id": "jMdlz4LXmPzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_salary(row):\n",
        "    balance = row.Balance\n",
        "    salary = row.EstimatedSalary\n",
        "    return balance/salary"
      ],
      "metadata": {
        "id": "WUY1qTafmlP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit Score Squared"
      ],
      "metadata": {
        "id": "TyEEcbOwmlo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def credit_score_squared(row):\n",
        "    return (row.CreditScore)**2"
      ],
      "metadata": {
        "id": "oQDDTRf6mn4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Financial Condition (Financial Health)"
      ],
      "metadata": {
        "id": "d0qV6bOVmsTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_financials(row):\n",
        "    credit_score = row.CreditScore\n",
        "    balance = row.Balance\n",
        "    estimated_salary = row.EstimatedSalary\n",
        "\n",
        "    mean_financials = (credit_score + balance + estimated_salary) / 3\n",
        "    return mean_financials"
      ],
      "metadata": {
        "id": "t_l8RrDimuES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Feature Engineering"
      ],
      "metadata": {
        "id": "CevcVVNomwMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(df, is_show_graph=False):\n",
        "    df_fe = df.copy()\n",
        "\n",
        "    # balance_salary_rate\n",
        "    df_fe['balance_salary_rate'] = df_fe.apply(lambda x:balance_salary(x), axis=1)\n",
        "\n",
        "    # product_utilization_rate_by_year\n",
        "    df_fe = df_fe.assign(product_utilization_rate_by_year=df_fe.apply(lambda x:product_utilization_rate_by_year(x), axis=1))\n",
        "\n",
        "    # product_utilization_rate_by_estimated_salary\n",
        "    df_fe = df_fe.assign(product_utilization_rate_by_estimated_salary=df_fe.apply( lambda x: product_utilization_rate_by_estimated_salary(x), axis=1))\n",
        "\n",
        "    # tenure_rate_by_age\n",
        "    df_fe['tenure_rate_by_age'] = df_fe.Tenure / (df_fe.Age - 17)\n",
        "\n",
        "    # credit_score_rate_by_age\n",
        "    df_fe['credit_score_rate_by_age'] = df_fe.CreditScore / (df_fe.Age - 17)\n",
        "\n",
        "    # product_utilization_rate_by_salary\n",
        "    df_fe['product_utilization_rate_by_salary'] = df_fe.Tenure /(df_fe.EstimatedSalary)\n",
        "\n",
        "    # credit_score_rate_by_salary\n",
        "    df_fe['credit_score_rate_by_salary'] = df_fe.CreditScore /(df_fe.EstimatedSalary)\n",
        "\n",
        "    # mean_financials\n",
        "    df_fe['mean_financials'] = df_fe.apply(lambda x: mean_financials(x), axis=1)\n",
        "\n",
        "    # credit_score_squared\n",
        "    df_fe['credit_score_squared'] = df_fe.apply(lambda x: credit_score_squared(x), axis=1)\n",
        "\n",
        "    # age_tenure\n",
        "    df_fe['age_tenure'] = df_fe.apply(lambda x: age_tenure(x), axis=1)\n",
        "\n",
        "    # age_categorization\n",
        "    df_fe['age_categorization'] = df_fe.Age.apply(lambda x: age_categorization(x))\n",
        "\n",
        "    # credit_score_table\n",
        "    df_fe = df_fe.assign(credit_score_table=df_fe.apply(lambda x:credit_score_table(x), axis=1))\n",
        "\n",
        "    # countries_monthly_average_salaries\n",
        "    df_fe = df_fe.assign(countries_monthly_average_salaries=df_fe.apply(lambda x: countries_monthly_average_salaries(x), axis=1))\n",
        "\n",
        "    if is_show_graph:\n",
        "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 12))\n",
        "        fig.tight_layout()\n",
        "\n",
        "        sns.boxplot(y='balance_salary_rate', x=TARGET, hue=TARGET, data=df_fe, ax=axes[0][0])\n",
        "        sns.boxplot(y='product_utilization_rate_by_year', x=TARGET, hue=TARGET, data=df_fe, ax=axes[0][1])\n",
        "        plt.ylim(-1, 5)\n",
        "\n",
        "    return df_fe"
      ],
      "metadata": {
        "id": "o91v2s-Dmxnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Encoding"
      ],
      "metadata": {
        "id": "lZoYQ9aNnJb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_encoding(df):\n",
        "    df_model = df.copy()\n",
        "\n",
        "    # Categorical columns\n",
        "    non_encoding_columns = [\"Geography\", \"HasCrCard\", \"IsActiveMember\", \"Gender\", \"NumOfProducts\", \"Tenure\", \"credit_score_table\",\"age_categorization\"]\n",
        "    df_non_encoding = df_model[non_encoding_columns]\n",
        "    df_model = df_model.drop(non_encoding_columns, axis=1)\n",
        "\n",
        "    df_encoding = df_non_encoding.copy()\n",
        "\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    encoder = LabelEncoder()\n",
        "    df_encoding[\"gender_category\"] = encoder.fit_transform(df_non_encoding.Gender)\n",
        "    df_encoding[\"country_category\"] = encoder.fit_transform(df_non_encoding.Geography)\n",
        "    df_encoding[\"credit_score_category\"] = encoder.fit_transform(df_non_encoding.credit_score_table)\n",
        "    df_encoding[\"age_category\"] = encoder.fit_transform(df_non_encoding.age_categorization)\n",
        "\n",
        "    df_encoding.reset_index(drop=True, inplace=True)\n",
        "    df_model.reset_index(drop=True, inplace=True)\n",
        "    df_model = pd.concat([df_model, df_encoding], axis=1)\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    df_model = df_model.drop([\"Geography\", \"Gender\", \"CustomerId\", \"Surname\", \"credit_score_table\",\"age_categorization\"], axis=1)\n",
        "\n",
        "    # Encode HasCrCard and IsActiveMember as -1 for 0 values\n",
        "    df_model.loc[df_model.HasCrCard == 0, 'HasCrCard'] = -1\n",
        "    df_model.loc[df_model.IsActiveMember == 0, 'IsActiveMember'] = -1\n",
        "\n",
        "    return df_model\n",
        "\n",
        "data_encoded = data_encoding(data_feature)\n",
        "data_encoded.head(20)"
      ],
      "metadata": {
        "id": "J5dfYIgenTWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Analysis"
      ],
      "metadata": {
        "id": "hysP35KFnaep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = data_encoded.corr().abs()\n",
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(correlation, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wD_t-32Xnb8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Utilization"
      ],
      "metadata": {
        "id": "OekXbGMkndZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_prepare(df_model):\n",
        "    y = df_model[TARGET]\n",
        "    X = df_model.drop(TARGET, axis=1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=32)\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "# model_prepare test, train split 0.3\n",
        "X_train, X_test, y_train, y_test = model_prepare(df_model = data_encoded)"
      ],
      "metadata": {
        "id": "NDFnD6Uxnfus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "V2PXYNH6nhzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logr_model = LogisticRegression()\n",
        "logr_model.fit(X_train, y_train)\n",
        "y_pred = logr_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "print(f\"Accuracy score of Logistic Regression: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "G13d_5DznkVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with Training"
      ],
      "metadata": {
        "id": "ovMcuHtCnmZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_training(X_train, X_test, y_train, y_test):\n",
        "    models = [\n",
        "        ('LOGR', LogisticRegression()),\n",
        "        ('KNN', KNeighborsClassifier()),\n",
        "        ('CART', DecisionTreeClassifier()),\n",
        "        ('RF', RandomForestClassifier()),\n",
        "        ('GBM', GradientBoostingClassifier()),\n",
        "        ('XGBoost', XGBClassifier()),\n",
        "        ('LightGBM', LGBMClassifier()),\n",
        "        ('CatBoost', CatBoostClassifier(verbose=0))\n",
        "        ]\n",
        "\n",
        "\n",
        "    df_result = pd.DataFrame(columns=[\"model\", \"accuracy_score\", \"scale_method\", \"0_precision\", \"0_recall\", \"1_precision\", \"1_recall\"])\n",
        "    for name, model in models:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        score = accuracy_score(y_test, y_pred)\n",
        "        class_report = classification_report(y_test, y_pred, digits=2, output_dict=True)\n",
        "        zero_report = class_report['0']\n",
        "        one_report = class_report['1']\n",
        "        df_result = pd.concat([df_result, pd.DataFrame({\n",
        "            'model': [name],\n",
        "            'accuracy_score': [score],\n",
        "            'scale_method': ['NA'],\n",
        "            '0_precision': [zero_report['precision']],\n",
        "            '0_recall': [zero_report['recall']],\n",
        "            '1_precision': [one_report['precision']],\n",
        "            '1_recall': [one_report['recall']]\n",
        "        })], ignore_index=True)\n",
        "\n",
        "    return\n",
        "    df_result.sort_values(\"accuracy_score\", ascending=False)\n",
        "    training_result = data_training(X_train, X_test, y_train, y_test)\n",
        "    training_result"
      ],
      "metadata": {
        "id": "CYfw3OVanofN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "TBfGA2-dnr8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "8R4Hdyfdnw9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(objective='reg:logistic',\n",
        "eval_metric=\"logloss\")\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.3, 0.31, 0.32],\n",
        "    'max_depth': [5,6,7],\n",
        "    'n_estimators': [30,40, 50]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "\n",
        "\n",
        "xgb_model=XGBClassifier(silent=0, learning_rate=0.31,\n",
        "max_delta_step=5,\n",
        "                            objective='reg:logistic',n_estimators=30,\n",
        "77\n",
        "\n",
        "                            max_depth=3, eval_metric=\"logloss\",\n",
        "gamma=3,base_score=0.5)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "print(classification_report(y_test,y_pred,digits=2))\n",
        "print(\"Accuracy score of Tuned XGBoost Regression: \",\n",
        "accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "JDbq1hnjnynT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "wG1JchTpn2gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'max_depth': [6, 7, 8], 'max_features':\n",
        "[7,8,9],'n_estimators' : [50,100], 'min_samples_split': [5, 6, 7]}\n",
        "randFor_grid = GridSearchCV(RandomForestClassifier(), param_grid, cv =\n",
        "3, refit = True, verbose = 0)\n",
        "randFor_grid.fit(X_train,y_train)\n",
        "y_pred = randFor_grid.predict(X_test)\n",
        "print(classification_report(y_test,y_pred,digits=2))\n",
        "print(\"Accuracy score of tuned Random Forest model: \",\n",
        "accuracy_score(y_test, y_pred))\n",
        "rnd_model = RandomForestClassifier(max_depth=10, max_features=14,\n",
        "min_samples_split=11,n_estimators=75)\n",
        "rnd_model.fit(X_train, y_train)\n",
        "y_pred = rnd_model.predict(X_test)\n",
        "print(classification_report(y_test,y_pred,digits=2))\n",
        "print(\"Accuracy score of tuned Random Forest model: \",\n",
        "accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "yTpSqnr0n4jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightBGM"
      ],
      "metadata": {
        "id": "D0-xgdHJn6h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_model = LGBMClassifier(silent = 0, learning_rate = 0.08,\n",
        "max_delta_step = 1, n_estimators = 45, boosting_type = 'gbdt',\n",
        "                            max_depth = 5)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "y_pred = lgbm_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, digits=2))\n",
        "print(\"Accuracy score of tuned LightGBM model: \", accuracy_score(y_test,\n",
        "y_pred))"
      ],
      "metadata": {
        "id": "QLHtCxiMn9OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter and More Function"
      ],
      "metadata": {
        "id": "PxKtpOTHn_q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display the best model score and parameters\n",
        "def display_best_model(model):\n",
        "    print(f\"Best score: {model.best_score_}\")\n",
        "    print(f\"Best parameters: {model.best_params_}\")\n",
        "    print(f\"Best estimator: {model.best_estimator_}\")\n",
        "\n",
        "# Function to calculate AUC score and ROC curve\n",
        "def calculate_auc_scores(y_actual, y_pred_prob):\n",
        "    auc_score = roc_auc_score(y_actual, y_pred_prob)\n",
        "    fpr, tpr, _ = roc_curve(y_actual, y_pred_prob)\n",
        "    return auc_score, fpr, tpr\n",
        "78\n",
        "\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False,\n",
        "title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, color=\"blue\")\n",
        "    plt.yticks(tick_marks, classes, color=\"blue\")\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"red\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Function to handle infinite values in a DataFrame\n",
        "def handle_infinite_values(df):\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)"
      ],
      "metadata": {
        "id": "1wUaDtn4oBx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confussion Matrix"
      ],
      "metadata": {
        "id": "FbePu0sMoF8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfm = confusion_matrix(y_test, y_pred=y_pred)\n",
        "plot_confusion_matrix(cfm, classes=['Non Churn','Churn'],\n",
        "                      title='Churn Confusion matrix')\n",
        "tn, fp, fn, tp = cfm.ravel()\n",
        "print(\"True Negatives: \",tn)\n",
        "print(\"False Positives: \",fp)\n",
        "print(\"False Negatives: \",fn)\n",
        "print(\"True Positives: \",tp)"
      ],
      "metadata": {
        "id": "8P4R4nJyoIVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve"
      ],
      "metadata": {
        "id": "exwFWP2OoKAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = lgbm_model.predict_proba(X_test)\n",
        "skplt.metrics.plot_roc_curve(y_test, y_pred_proba, figsize=(8,8))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zCHwSTmHoMCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance"
      ],
      "metadata": {
        "id": "t3NvhbMfoOC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_index = data_encoded.loc[:, data_encoded.columns != TARGET]\n",
        "\n",
        "feature_importance = pd.Series(xgb_model.feature_importances_,\n",
        "                               index=feature_index.columns).sort_value\n",
        " s(ascending=False)\n",
        "sns.barplot(x = feature_importance, y = feature_importance.index,\n",
        "color='r', saturation=1)\n",
        "plt.xlabel('Variable Severity Scores')\n",
        "plt.ylabel('Variables')\n",
        "plt.title('Variable Severity Levels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w8spFCusoP3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline"
      ],
      "metadata": {
        "id": "h341gIBDoRgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_prepare(df_model =\n",
        "data_encoded)\n",
        "\n",
        "pipe = Pipeline([('xgboost', xgb_model)])\n",
        "\n",
        "pipe.fit(X_train,y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred,digits=2))\n",
        "print(\"Accuracy score of Tuned XGBoost Regression: \",\n",
        "accuracy_score(y_test, y_pred))\n",
        "\n",
        "with open('pipeline.pickle','wb') as f:\n",
        "    pickle.dump(pipe, f)\n",
        "\n",
        "with open('pipeline.pickle','rb') as f:\n",
        "    loaded_pipe = pickle.load(f)\n",
        "\n",
        "y_pred = loaded_pipe.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred,digits=2))\n",
        "80\n",
        "\n",
        "print(\"Accuracy score of Tuned XGBoost Regression: \",\n",
        "accuracy_score(y_test, y_pred))\n",
        "\n",
        "def prediction(model, df):\n",
        "    data_feature = feature_engineering(df)\n",
        "    data_encoded = data_encoding(data_feature)\n",
        "\n",
        "    prediction = model.predict(data_encoded)\n",
        "\n",
        "    df['ExitedPred'] = prediction.tolist()\n",
        "\n",
        "    return prediction\n",
        "with open('churn_model.pkl','wb') as f:\n",
        "    pickle.dump(xgb_model, f)\n",
        "\n",
        "with open('churn_model.pkl','rb') as f:\n",
        "    loaded_pipe = pickle.load(f)\n",
        "\n",
        "y_pred = loaded_pipe.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred,digits=2))\n",
        "print(\"Accuracy score of Tuned XGBoost Regression: \",\n",
        "accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "qQ1LRXwxoYWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}